{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install textdistance -q"
      ],
      "metadata": {
        "id": "MslOjasDttrd"
      },
      "id": "MslOjasDttrd",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import textdistance\n",
        "from tqdm import tqdm\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
      ],
      "metadata": {
        "id": "IewLhb5dtTrU"
      },
      "id": "IewLhb5dtTrU",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation += \"«»—…“”\""
      ],
      "metadata": {
        "id": "j_e6016Aw10E"
      },
      "id": "j_e6016Aw10E",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "371970ff",
      "metadata": {
        "id": "371970ff"
      },
      "source": [
        "# Домашнее задание № 3. Исправление опечаток"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b35cf8bd",
      "metadata": {
        "id": "b35cf8bd"
      },
      "source": [
        "## 1. Доп. ранжирование по вероятности (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6be25c",
      "metadata": {
        "id": "0c6be25c"
      },
      "source": [
        "Дополните get_closest_hybrid_match в семинаре так, чтобы из кандадатов с одинаковым расстоянием редактирования выбиралось наиболее вероятное."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
        "true = open('correct_sents.txt', encoding='utf8').read().splitlines()\n",
        "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()"
      ],
      "metadata": {
        "id": "Yg_kSkLSthdU"
      },
      "id": "Yg_kSkLSthdU",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_words(sent_1, sent_2):\n",
        "    tokens_1 = sent_1.lower().split()\n",
        "    tokens_2 = sent_2.lower().split()\n",
        "\n",
        "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
        "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
        "\n",
        "    tokens_1 = [token for token in tokens_1 if token]\n",
        "    tokens_2 = [token for token in tokens_2 if token]\n",
        "\n",
        "    assert len(tokens_1) == len(tokens_2)\n",
        "\n",
        "    return list(zip(tokens_1, tokens_2))"
      ],
      "metadata": {
        "id": "ROBsDcOgwrXs"
      },
      "id": "ROBsDcOgwrXs",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter(re.findall(r'\\w+', corpus.lower()))\n",
        "\n",
        "word2id = list(vocab.keys())\n",
        "id2word = {i:word for i, word in enumerate(vocab)}\n",
        "\n",
        "vec = CountVectorizer(analyzer='char', max_features=10000, ngram_range=(1,3))\n",
        "X = vec.fit_transform(vocab)"
      ],
      "metadata": {
        "id": "rKX0clCCtJZk"
      },
      "id": "rKX0clCCtJZk",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_closest_match_vec(text, X, vec, topn=20):\n",
        "    v = vec.transform([text])\n",
        "\n",
        "    similarities = cosine_distances(v, X)[0]\n",
        "    topn = similarities.argsort()[:topn]\n",
        "\n",
        "    return [(id2word[top], similarities[top]) for top in topn]"
      ],
      "metadata": {
        "id": "-Lxk1NwotHc3"
      },
      "id": "-Lxk1NwotHc3",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f8e8814a",
      "metadata": {
        "id": "f8e8814a"
      },
      "outputs": [],
      "source": [
        "def get_closest_match_with_metric(text, lookup,topn=20, metric=textdistance.levenshtein):\n",
        "    # Counter можно использовать и с не целыми числами\n",
        "    similarities = Counter()\n",
        "\n",
        "    for word in lookup:\n",
        "        similarities[word] = metric.normalized_similarity(text, word)\n",
        "\n",
        "    return similarities.most_common(topn)\n",
        "\n",
        "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
        "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
        "    lookup = [cand[0] for cand in candidates]\n",
        "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
        "\n",
        "    return closest\n",
        "\n",
        "N = sum(vocab.values())\n",
        "\n",
        "def P(word, N=N):\n",
        "    return vocab[word] / N\n",
        "\n",
        "def predict_mistaken(word, vocab):\n",
        "    return 0 if word in vocab else 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "e67f8d02",
      "metadata": {
        "id": "e67f8d02"
      },
      "outputs": [],
      "source": [
        "# новая функция\n",
        "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
        "    if text in vocab:\n",
        "        return text\n",
        "\n",
        "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
        "    lookup = [cand[0] for cand in candidates]\n",
        "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
        "\n",
        "    max_metr = max([word[1] for word in closest])\n",
        "\n",
        "    new_closest = {}\n",
        "    for word, metr in closest:\n",
        "        if metr == max_metr:\n",
        "            new_closest[word] = P(word)\n",
        "\n",
        "    max_word = None\n",
        "    max_value = float('-inf')\n",
        "    for word, value in new_closest.items():\n",
        "        if value > max_value:\n",
        "            max_value = value\n",
        "            max_word = word\n",
        "\n",
        "    return max_word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mistakes = []\n",
        "total_mistaken = 0\n",
        "mistaken_fixed = 0\n",
        "\n",
        "total_correct = 0\n",
        "correct_broken = 0\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "cashed = {}\n",
        "for i in tqdm(range(len(true))):\n",
        "    word_pairs = align_words(true[i], bad[i])\n",
        "    for pair in word_pairs:\n",
        "        if predict_mistaken(pair[1], vocab):\n",
        "            pred = cashed.get(pair[1], get_closest_hybrid_match(pair[1], X, vec)[0][0])\n",
        "            cashed[pair[1]] = pred\n",
        "        else:\n",
        "            pred = pair[1]\n",
        "\n",
        "        if pred == pair[0]:\n",
        "            correct += 1\n",
        "        else:\n",
        "            mistakes.append((pair[0], pair[1], pred))\n",
        "        total += 1\n",
        "\n",
        "        if pair[0] == pair[1]:\n",
        "            total_correct += 1\n",
        "            if pair[0] != pred:\n",
        "                correct_broken += 1\n",
        "        else:\n",
        "            total_mistaken += 1\n",
        "            if pair[0] == pred:\n",
        "                mistaken_fixed += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGjWS1WQvbjk",
        "outputId": "84790e7b-3b1f-4ec5-f14b-2f58f2500fe1"
      },
      "id": "HGjWS1WQvbjk",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 915/915 [18:11<00:00,  1.19s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct/total)\n",
        "print(mistaken_fixed/total_mistaken)\n",
        "print(correct_broken/total_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TmggKDWvcNE",
        "outputId": "a18ce635-d4bd-4c3c-87f1-ea7e8fdb245f"
      },
      "id": "-TmggKDWvcNE",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7928964482241121\n",
            "0.0015527950310559005\n",
            "0.09004249454461927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9cf9985",
      "metadata": {
        "id": "f9cf9985"
      },
      "source": [
        "## 2.  Symspell (7 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9392cc23",
      "metadata": {
        "id": "9392cc23"
      },
      "source": [
        "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Он основан только на одной операции - удалении символа. Описание алгоритма по шагам:\n",
        "\n",
        "1) Составляется словарь правильных слов  \n",
        "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово  (!)\n",
        "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
        "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  \n",
        "\n",
        "\n",
        "Оцените качество полученного алгоритма теми же тремя метриками."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee4b28f",
      "metadata": {
        "id": "dee4b28f"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_deletion_set(word):\n",
        "    deletion_set = set()\n",
        "    deleted_words = []\n",
        "    for i in range(len(word) + 1):\n",
        "        deleted_words.append((word[:i], word[i:]))\n",
        "        for left, right in deleted_words:\n",
        "            if right:\n",
        "                deletion_set.add(left + right[1:])\n",
        "    return deletion_set\n",
        "\n",
        "deletion_dict = {}\n",
        "\n",
        "sorted_words = sorted(vocab.keys(), key=vocab.get)\n",
        "\n",
        "for current_word in sorted_words:\n",
        "    for deleted_word in get_deletion_set(current_word):\n",
        "        deletion_dict[deleted_word] = deleted_word\n",
        "    deletion_dict[current_word] = current_word\n",
        "\n",
        "deletion_set = set(deletion_dict)"
      ],
      "metadata": {
        "id": "2xQxZZpFMaAj"
      },
      "id": "2xQxZZpFMaAj",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_word(word):\n",
        "    if word in vocab:\n",
        "        return word\n",
        "\n",
        "    del_set = get_deletion_set(word)\n",
        "    deletion_union = del_set.union({word})\n",
        "\n",
        "    deletion_intersection = tuple(deletion_union.intersection(deletion_set))\n",
        "\n",
        "    intersection_len = len(deletion_intersection)\n",
        "    if intersection_len == 0:\n",
        "        return word\n",
        "    elif intersection_len == 1:\n",
        "        return deletion_dict[deletion_intersection[0]]\n",
        "    else:\n",
        "        max_value = None\n",
        "        max_key = None\n",
        "\n",
        "        for word in deletion_intersection:\n",
        "            value = deletion_dict[word]\n",
        "            if max_value is None or P(value) > P(max_value):\n",
        "                max_value = value\n",
        "                max_key = word\n",
        "\n",
        "        return max_key"
      ],
      "metadata": {
        "id": "Q8KRt3DNe2wd"
      },
      "id": "Q8KRt3DNe2wd",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistakes = []\n",
        "total_mistaken = 0\n",
        "mistaken_fixed = 0\n",
        "\n",
        "total_correct = 0\n",
        "correct_broken = 0\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "cashed = {}\n",
        "for i in tqdm(range(len(true))):\n",
        "    word_pairs = align_words(true[i], bad[i])\n",
        "    for pair in word_pairs:\n",
        "        if predict_mistaken(pair[1], vocab):\n",
        "            pred = cashed.get(pair[1], correct_word(pair[1]))\n",
        "            cashed[pair[1]] = pred\n",
        "        else:\n",
        "            pred = pair[1]\n",
        "\n",
        "        if pred == pair[0]:\n",
        "            correct += 1\n",
        "        else:\n",
        "            mistakes.append((pair[0], pair[1], pred))\n",
        "        total += 1\n",
        "\n",
        "        if pair[0] == pair[1]:\n",
        "            total_correct += 1\n",
        "            if pair[0] != pred:\n",
        "                correct_broken += 1\n",
        "        else:\n",
        "            total_mistaken += 1\n",
        "            if pair[0] == pred:\n",
        "                mistaken_fixed += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8pKktjznwcr",
        "outputId": "9ba86015-9258-4c42-d26d-1d487c9b0da1"
      },
      "id": "M8pKktjznwcr",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 915/915 [00:00<00:00, 9754.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct/total)\n",
        "print(mistaken_fixed/total_mistaken)\n",
        "print(correct_broken/total_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Pbjlnbod-e",
        "outputId": "5fb1b902-674a-4436-add9-05ac8561efe0"
      },
      "id": "W0Pbjlnbod-e",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8456228114057028\n",
            "0.13043478260869565\n",
            "0.04858160101068106\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}