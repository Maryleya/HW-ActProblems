{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install razdel -q\n",
        "!pip install nltk -q"
      ],
      "metadata": {
        "id": "2P1J-JWTu5Xr"
      },
      "id": "2P1J-JWTu5Xr",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b20f786e",
      "metadata": {
        "id": "b20f786e"
      },
      "source": [
        "# Домашнее задание № 2. Мешок слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "129c4d2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "129c4d2e",
        "outputId": "4d8650e0-5473-4298-d6e8-8cb80daa6f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import razdel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf72d19",
      "metadata": {
        "id": "0cf72d19"
      },
      "source": [
        "## Задание 1 (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a045e99",
      "metadata": {
        "id": "4a045e99"
      },
      "source": [
        "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90b4d453",
      "metadata": {
        "id": "90b4d453"
      },
      "source": [
        "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя.\n",
        "\n",
        "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4314de5",
      "metadata": {
        "id": "b4314de5"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('labeled.csv')\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
        "train.reset_index(inplace=True)\n",
        "test.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbffbbc7",
      "metadata": {
        "id": "cbffbbc7"
      },
      "outputs": [],
      "source": [
        "# дефолтная токенизация\n",
        "vectorizer = TfidfVectorizer(min_df=5, max_df=0.4)\n",
        "\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(X, y)\n",
        "preds = clf.predict(X_test)\n",
        "print(classification_report(y_test, preds, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB8mpp9Nt2zi",
        "outputId": "cee5f44e-5bcf-4fb9-c8f2-f39d5d5d2368"
      },
      "id": "rB8mpp9Nt2zi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.96      0.89       945\n",
            "         1.0       0.89      0.60      0.72       497\n",
            "\n",
            "    accuracy                           0.84      1442\n",
            "   macro avg       0.86      0.78      0.80      1442\n",
            "weighted avg       0.85      0.84      0.83      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "    tokenized_text = []\n",
        "    for word in razdel.tokenize(text):\n",
        "        tokenized_text.append(word.text)\n",
        "    return tokenized_text"
      ],
      "metadata": {
        "id": "-NWGSSEjv9PO"
      },
      "id": "-NWGSSEjv9PO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# razdel токенизация\n",
        "vectorizer = TfidfVectorizer(tokenizer=tokenizer, min_df=5, max_df=0.4)\n",
        "\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m1DvKOQuyM6",
        "outputId": "351e37ec-8d6d-46ed-e1ba-4ee39c51af80"
      },
      "id": "4m1DvKOQuyM6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(X, y)\n",
        "preds = clf.predict(X_test)\n",
        "print(classification_report(y_test, preds, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P69-veIgwx6d",
        "outputId": "b11c1792-64b8-485b-cb8f-d55a6e813853"
      },
      "id": "P69-veIgwx6d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.95      0.88       945\n",
            "         1.0       0.86      0.60      0.71       497\n",
            "\n",
            "    accuracy                           0.83      1442\n",
            "   macro avg       0.84      0.78      0.80      1442\n",
            "weighted avg       0.84      0.83      0.82      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики получились практически одинаковыми, но у razdel все-таки немного меньше."
      ],
      "metadata": {
        "id": "oY7bon9IxPau"
      },
      "id": "oY7bon9IxPau"
    },
    {
      "cell_type": "markdown",
      "id": "91b9076e",
      "metadata": {
        "id": "91b9076e"
      },
      "source": [
        "## Задание 2 (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e25357",
      "metadata": {
        "id": "14e25357"
      },
      "source": [
        "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7de962ad",
      "metadata": {
        "id": "7de962ad"
      },
      "source": [
        "Требования к моделям:   \n",
        "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
        "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
        "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
        "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
        "\n",
        "*random_seed не считается за параметр"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ac0a5471",
      "metadata": {
        "id": "ac0a5471"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('labeled.csv')\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
        "train.reset_index(inplace=True)\n",
        "test.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "russian_stopwords = stopwords.words('russian')"
      ],
      "metadata": {
        "id": "ODfpDENMz8-w"
      },
      "id": "ODfpDENMz8-w",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "745bd58f",
      "metadata": {
        "id": "745bd58f"
      },
      "outputs": [],
      "source": [
        "# логистическая регрессия с tf-idf векторайзером\n",
        "vectorizer = TfidfVectorizer(min_df=5, max_df=0.4, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
        "\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90311fac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90311fac",
        "outputId": "40e8dabe-e66c-4b97-8947-6437cadd3a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.85      0.87       947\n",
            "         1.0       0.74      0.80      0.77       495\n",
            "\n",
            "    accuracy                           0.83      1442\n",
            "   macro avg       0.81      0.83      0.82      1442\n",
            "weighted avg       0.84      0.83      0.84      1442\n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(penalty='l2', class_weight='balanced')\n",
        "clf.fit(X, y)\n",
        "preds = clf.predict(X_test)\n",
        "print(classification_report(y_test, preds, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = vectorizer.transform(data.comment)\n",
        "probas = clf.predict_proba(vectors)\n",
        "text_proba = {}\n",
        "for text, proba in zip(data.comment, probas):\n",
        "    text_proba[text] = proba[1]\n",
        "\n",
        "cnt = Counter(text_proba)\n",
        "cnt.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJWvA0U728F8",
        "outputId": "5bbc6a2d-0814-493b-bcf6-494ca68b470f"
      },
      "id": "ZJWvA0U728F8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Нахуй иди чмо ебаное, рот твой ебал. Говна поешь, быдло\\n',\n",
              "  0.9973361631087458),\n",
              " ('Нахуй иди, я тебе весь тред что ли читать буду? Пидор, бешбармак тебе в хычин!\\n',\n",
              "  0.9965190458227453),\n",
              " ('АЛЛО БЛЯДЬ АБУ ТЫ Ч ОХУЕЛ? ВЫГОНЯЙ НАХУЙ СВОЕГО ПОДЗАЛУПНОГО ДРУЖКА ВАРЛАМОВА НАХУЙ ИЗ Б ЭТА ХУЙНЯ ЗАЕБАЛА В 5 ТРЕДОВ БЛЯДЬ НА ГЛАВНОЙ ВИСЕТЬ, БАНЫЙ ТВОЙ РОТ ДЫРЯВЫЙ БЛЯДЬ, ПРОДАЖНАЯ МРАЗЬ!\\n',\n",
              "  0.9960805712922417),\n",
              " ('ИДИ НАХУЙ, СУКА, ЗАВАЛИ ЕБАЛО, БЛЯТЬ\\n', 0.9949596706615794),\n",
              " ('Хохлы-объебосы порвались, лол\\n', 0.9939471429982177),\n",
              " ('Ну оль, ну вот че тебе надо? Иди в по сри, а этот достопочтенный тред оставь в покое\\n',\n",
              "  0.993914966366831),\n",
              " ('Так воюют Русские А так воюют хохлы\\n', 0.9938457427661792),\n",
              " ('Блядь абу нахуй ссылай этих дегенератов в фаг, всем похуй на их шлюх\\n',\n",
              "  0.9935381495097249),\n",
              " ('Ебать вы тупые дебилы, ой блять\\n', 0.9926436967666499),\n",
              " ('Шмароёб реально задолбал. Зачем он срёт этой шалавой? В одиночестве пусть шышку хоть до основания стирает, но нахуй она на автаче если у неё, блять, ДАЖЕ ПРАВ НЕТ?! БУНД блядь!\\n',\n",
              "  0.9923901965577976)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# наивный байесовский классификатор с count векторайзером\n",
        "vectorizer = CountVectorizer(min_df=3, max_df=0.4, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
        "\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ],
      "metadata": {
        "id": "UQCQHAht0wLf"
      },
      "id": "UQCQHAht0wLf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MultinomialNB(alpha=1, force_alpha=True)\n",
        "clf.fit(X, y)\n",
        "preds = clf.predict(X_test)\n",
        "print(classification_report(y_test, preds, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e6Sdygu1Qmt",
        "outputId": "60b65a57-8774-41db-cea3-8236db500e5c"
      },
      "id": "-e6Sdygu1Qmt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.90      0.88       947\n",
            "         1.0       0.79      0.71      0.75       495\n",
            "\n",
            "    accuracy                           0.84      1442\n",
            "   macro avg       0.82      0.81      0.81      1442\n",
            "weighted avg       0.83      0.84      0.83      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = vectorizer.transform(data.comment)\n",
        "probas = clf.predict_proba(vectors)\n",
        "text_proba = {}\n",
        "for text, proba in zip(data.comment, probas):\n",
        "    text_proba[text] = proba[1]\n",
        "\n",
        "cnt = Counter(text_proba)\n",
        "cnt.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igYygCyg4xW2",
        "outputId": "6f1d9a9d-0dca-4a1a-b1b9-a1f5155374a4"
      },
      "id": "igYygCyg4xW2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Возьмём как пример Россию, западноевропейские страны и США. Идёт метисация, сознательная политика замещения белого населения на пришлое черно-коричневое. Идёт создание новой расы метисов, исламизация и почернение. В крупных городах половина населения - выходцы из ебеней Мексики, Африки, Ближнего Востока, а в случае с Россией - Кавказа и Средней Азии. Этнические ниггеро-арабские гетто верят на хую законы как хотят, чудовищная по масштабам этническая преступность. Говорить о миграции и тем более затрагивать тему замещения коренного населения властями нельзя, иначе бутылка. Свобода слова тут не для вас, молодой человек. При этом говорить о том, что белые должны вымереть, и это нормально - можно. Белые официально вымирают ведётся пропаганда так или иначе направленная на снижение рождаемости белого населения. Феминизм, ЛГБТ, чайлдфри. Каждая женщина в Швеции - леволиберальная феминистка, это страна победившего феминизма. Что сегодня там происходит - страшно делается. Пропагандируются смешанные браки, межрасовые браки, пропагандируется превосходство детей-метисов. Идёт демонизация белых и пропаганда превосходства чёрных и смуглых мужчин, форс отношений белая женщина смуглый чёрный мужчина-мигрант. Как результат - всё больше чернильниц, всё больше смешанных браков, всё больше небелых метисов. Белые женщины просто не хотят контактировать с мужчинами своей нации и расы, наделяя их самыми плохими качествами и обожествляя черных. При этом большинство белых не считает завоз чурок чем-то плохим, наоборот, относятся к ним толерантно. Проводится политика насаждения толерантности, мультикультурализма, политкорректности и космополитизма. Набирающее популярность даже в России SJW - это вообще отдельная тема для обсуждения. Всё вышеперечисленное относится к сильнейшим когда-то странам, бывшим империям, нагибающим слабых. Сегодня происходит так, что бывшие империи в прямом смысле деградируют, вырождаются и вымирают, а место сильнейших когда-то, господствующих народов, занимают те, кого когда-то колонизировали. Во Франции к 2080 уже будут доминировать негры и арабы, в России - кавказцы и выходцы из средней Азии, в Великобритании - индийцы, негры, арабы, пакистанцы, etc. А в маленьких, нейтральных странах, вроде Словении или Беларуси, Литвы или Чехии, Румынии или Эстонии - всё пучком. Им вымирание не грозит, они остаются и будут оставаться белыми. Более того, у них ведётся политика, направленная на сохранение традиционных ценностей и культуры коренного населения. Они сказали беженцам нет . В Польшу, например, русскому или украинцу гораздо легче переехать и остаться, чем арабу или африканцу. В Германии ситуация противоположная, белых там не ждут. Польша, Чехия, Словакия, Венгрия, Словения, Хорватия, Сербия, БиГ, Черногория, Македония, Греция, Болгария, Румыния, Молдова, Украина, Беларусь, Литва, Латвия, Эстония - вот Европа будущего. Скандинавия, Южная, Западная Европа, а также Россия - лишатся коренного населения и своей культуры.\\n',\n",
              "  1.0),\n",
              " ('Ну давай разберём всё тобой написанное. Бляядь, вы действительно думаете вы лучше пидорашек? Ну в целом, всё что живёт в рашке - затронуто говномидасом, но никто тут это не признает. сейчас воспитывают массу хороших кодеров В соседнем треде обоссали уже. Иди обтекай. Вы унижаете русских детей в школе Я учился в рашке и у нас был класс, который состоял онли из русачков. Думаешь, что то изменилось? Чурки тебе говна в жопу залили и заставили русачков в классе кошмарить омежных русачков? Я не люблю выражаться фразами нациков, но вы воистину столетия просто сидели в горах и ебали баранов, вас даже народ-пидор смог захватить. Плоховато ты знаешь историю. Когда русня пришла на Кавказ, тут всё уже было поделено османами и персами. А потом РИ наебала персов и постоянно нападала на османов высасывая причины из пальца, в принципе, русачки, что от них ещё было ожидать. В прошлом вы (чеченцы, даги и прочие сорта) были просто дикарями...А если говорить о среднеазиатах, которые бугуртят с оккупации, то вы были обычными нищими кочевниками Очередной акт незнания истории. Например у кавказцев по факту у народов отвественных за этногенез дагов и азеров уже был Дербент, а русачков даже в планах не было. Почитай историю Кавказа и Средней Азии, там были и локальные империи и нагибы округи и прочее и прочее. Называют русских пидорашками, славщитом. Говоришь это так, будто бы в этом что то плохое. У меня знакомые po рашеры irl, которые являются русскими и которые ссут на русню с ещё большей колокольни чем я Сейчас вас все боятся потому, что если пидорашка сделает в вас пару дырок, защищая себя, то его посадят на бутылку, а если вы убьёте пидорашку, то вам нихуя не будет. Может потому что в рашке мочить с волыны ножа человека, который идёт на тебя с кулаками - превышение пределов самообороны? Кто виноват в том, что русня настолько вырожденческая, что один чеченский доходяга ставит на колени группу русачков? Ты думаешь, будь руснявая гопота менее вырожденческая, то так же людей не кошмарила? Кто виноват, что вы морозитесь или даёте по съебатору, когда видите, как вашего славянского друга избивают унижают? Да чего уж там, тот митинг вспомните, где жирик, какого то парня на колени поставил и все вокруг стоят и снимают, словно стадо руснявых баранов. Зуб даю, в той толпе стояли его друзья и знакомые. Лично для меня это пиздец, особенно проигрываю, когда там не какой нибудь братуха-борцуха, а смарчёк чеченский. Никогда бы не бросил и не бросал друга в таком пиздеце и не важно, какой нации был друг, а какой нападавший. Вся ваша проблема не том, что вы слабками, не в том, что большинство русачков еблом похож на свинью, не в том, что за тысячу лет существования не смогли построить нормальную цивилизацию и другим не давали. Проблема в обыкновенной ошибке выжившего, вы видите кавказское быдло гопника, потому что оно в среднем сильнее, напористее, агрессивнее и образ кавказца, как лица которое представляет опасность выжигается у вас в мозгах, при этом не хотите замечать, что у вас, целые города набитые руснявыми АУЕшниками, потому что один среднестатистический руснявый гопник ауешник быдлойд сосёт у одного среднестатистического чуркобесского гопника быдлойда. В конечном итоге русачков в станице кущевской ебал кто? Другие русачки. В школу приезжали и выберали лолей на поёбку кто? Другие русачки. Сжигал русачков кто? Другие русачки. Всё вскрылось совершенно случайно. Сколько таких станиц, деревень и городов по всей рашке? аз-кун\\n',\n",
              "  1.0),\n",
              " ('Твоих граждан ? Твои товары ? у ВАС растёт продолжительность жизни? Те гауляйтеры - это ты и твои хозяева-кормильцы, предающие и насилующие российский народ ЕЖЕДНЕВНО И ЕЖЕЧАСНО. Вы торгуете недрами, вы пытаетесь пристроить награбленное подальше от ограбляемогонарода, вы наполнили страну полицаями , защищающими исключительно ваши интересы от российского народа. Вы гоните в НАТО нефть, газ, лес и прочие ресурсы, которые воруете у россиян, вы обложили данью всех от мелких и крупных торговцев, до самозанятых , выживающих в беспределе грабежа и воровства, творимого вами в стране. Вы оплачиваете свои права кровью и потом народа. Свои права по уничтожению этого самого народа. Деньги ВЫ превратили в мерило прав. Право на здравоохранение, образование, защиту и все базовые права ВЫ требуете оплачивать, не считая людьми и гражданами никого, кроме тех,кто это всё оплатит звонкой монетой. И войска НАТО приведёте в страну тоже ВЫ. Своей неудержимой жаждой денег и власти. Так же, как это сделал ваш свято-кровавый николашка , приведя в Россию своих партнёров . Они - ВАШИ партнёры - не мои. Так вот, знайте. Когда ваши партнёры по грабительскому бизнесу придут лишать ВАС вашей доли, и вы, и они будут по другую сторону фронта от меня и российского народа - точно так же, как вы и они ВМЕСТЕ по другую сторону фронта экономического все последние 30 лет. Я за ваши головы не дам и гнилой картошины. Так что, бойтесь не их. Бойтесь нас. Они для меня - просто враги, а ВЫ - ПРЕДАТЕЛИ СОБСТВЕННОГО НАРОДА, говно безродное, НЕЛЮДИ. И только очистив страну от таких как вы, возможно её защитить от них. Запиши на обороте своей методички, и передай по команде.\\n',\n",
              "  1.0),\n",
              " ('Целью встречи стали переговоры о сохранении поставок газа А что, у него есть полномочия вести такие переговоры? Сука блядский цирк. Какие же хохлы дегенераты, пиздец просто\\n',\n",
              "  1.0),\n",
              " ('Очевидно, что топтать дворников и чем там ещё федоровичи по всей стране занимались- это просто другой уровень деятельности Вот и попался куколд-воевака. А гонору сколько было, да мы на дунбусее, да я в грозном двери настежь - давай говно на разы. Когда твою сестру будут насиловать черенком от веника три дворника, то ты будешь просто играть в Подземелья и Драконы и делать вид что ничего не происходит. А не, как Джимми Нейтрон напряжёшь мозги и будешь искать РЕЛЕВАНТНОЕ решение проблемы, пока сестричке, с венком ромашек на голове, раздирают дырочку. Ссали тебе в рот всем кондопогом, чека-нацианалистъ. Твои маняврирования от вопросов точно такое же тухлое пиздабольство как и на стремах жирного, можешь в гости записатся, если достаточно всратый для их патоков. Ах, да, а хули ты у мамы под юбкой, а не спасаешь наших новиопов в трусках от злых фашистов? За пять лет так и не собрался? Давай реще, чучело.\\n',\n",
              "  1.0),\n",
              " ('Игорь, ты? Помнишь меня? Я твой одноклассник. Я узнал тебя по твоим шизоидным словам и высерам. А помнишь, как мы всем классом нассали тебе в кружку в третьем классе, на сладкоежке? Ты ещё выпил, облизнулся и попросил добавки. А потом тебя пришёл забирать твой отец, тот самый дворник, который на Вернадского изнасиловал собаку и получил условный срок за то, что украл плавленный сырок в магазине. Он зашёл в класс, все стали смеяться, а ты обосрался под себя от стыда, а потом сказал, что всю жизнь будешь ненавидеть дворником, но в 9м классе, когда ты пошёл на рейд, чтобы их отпиздить, то они пустили тебя по кругу, после чего тебе наложили на анус восемь швов. Как поживаешь, Игорян?\\n',\n",
              "  1.0),\n",
              " ('Конечно, это резонансное событие требует отдельного треда для обсуждения и 19 тредов до этого шло обсуждение. Тред назывался нейтрально Рассстрел мусульман в новозеландской мечети . Но сегодня ОП, по совместительству борец за Арийскую Раssy и мамкин фашик назвал его в честь стрелка KEBAB REMOVER(англ. уничтожитель чурок ) и с утра пораньше решил в ОП-посте(заголовке треда) обозначить тред, как героизирующий(в первом треде) и оправдывающий(в третьем треде) терракт этого стрелка. Пик стронгли релейтед. 20 тред. В третьей строке заголовка ОП восхваляет и героизирует террориста, цитирую заголовок: KEBAB REMOVER тред 20 Продолжаем пиздеть тут. Слава Герою! Я репортил тред в форме репорта и в прикрепе в d , реакции никакой. Видимо, школомодеры сами симпатизируют нацизму и закрывают на это глаза. 21 тред. После того, как я пригрозил ему репортом, в этот раз мамкин фашик, убирает строку про героя и зачем-то вместо неё ставит нацистское приветствие дивизии СС Галичина. KEBAB REMOVER тред 21 Продолжаем пиздеть тут. Слава Украiнi! 22 тред. В этот раз тот же остроумный ОП поставил на третью строчку PRESS R TO PAY RESPECT!(англ. Нажмите R, чтобы выразить уважение!) т.е. уважение стрелку за то, что он совершил терракт. Еще он выделил жирным шрифтом предложение Именно эту мечеть он выбрал потому, что на её месте раньше находилась церковь. , будто то бы для оправдания стрелка. KEBAB REMOVER тред 22 Продолжаем пиздеть тут. PRESS R TO PAY RESPECT! Эти действия подпадают под конкретные статьи УК РФ, (публичное оправдание терроризма или пропаганда терроризма), а модерация никак не трёт такие заголовки треда, не реагирует на репорты. Да, я понимаю, что на Дваче возможна любая точка зрения, но хотя бы шапка треда должна быть нейтральной и уж точно не должна оправдывать и героизировать терроризм фашизм и не нарушать законодательство. Такое название треда автоматически собирает в нём нацистскую падаль и сворачивает обсуждение в сторону фашистской идеологии.\\n',\n",
              "  1.0),\n",
              " ('Создал тут тхреад в b 192441781 Как оказалось, ЛГБТ пропаганда в б кажется унылой и слишком обильной не только мне. Как насчёт пидорнуть все гее би треды из b в ga? Хуле они тут у себя филиал открыли? Заебали притеснять натуралов. Давайте я поясню. Пидоротреды унылы и неприятны, и их крайне много. Это заебало. Если куклоебов и пониебоы пидорнули, почему пидоров нельзя пидорнуть? Пониебы всех заебали - их пидорнули Куклоебы всех заебали - их пидорнули Пидоротреды заебали меня, я интересуюсь, сколько ещё анонов заебались их видить нонстоп 24 7 на главной. Если нас будет много - можно и пидорнуть, я считаю. Для них есть целый раздел, или 2-3 даже. Но все равно постоянно это лезет на главную в b. ДОКОЛЕ?\\n',\n",
              "  1.0),\n",
              " ('хорошо тут все ясно а теперь поясни мне за то что он кладет на репорты за шитпостинг и нерелейтед. айробусом дедом, лизон создали тред, карине создали тред, оляше создали тред, так какого хуя этим ебланам треды отдельные не создать? какого хуя ты тут чертила свой рот открываешь, тварь малолетняя, вот из за таких как ты уебанов все и скатилось в гавно, потому что черта этого никто не репортит, а такие говноеды как ты все сливают в парашу\\n',\n",
              "  1.0),\n",
              " ('моча сюда не заходит И как привлекать их внимание? Флешмоб организовать что-ли? Если будешь надоедать моче борьбой с поехавшим, то сам будешь не сильно отличаться от поехавшего. Спейсачерам просто пора научиться игнорировать этого идиота и просто бампать другие треды, вместо того чтобы отвечать шизику. Всё равно никто не хочет с ним говорить, но у него реально в голове иллюзия создается, что он какой-то интересный человек, хотя по сути ему на лицо ссут, а он думает что с ним нормально общаются. Я думаю с ним в жизни никто не общается и даже когда ему на лицо ссут, банят, посылают нахуй, он думает что это общение и радуется как ребенок.\\n',\n",
              "  1.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кажется, все тексты отличаются, и все тексты токсичные. У второго классификатора все самые токсичные тексты получились длиннее."
      ],
      "metadata": {
        "id": "-3LGAGvV5KLE"
      },
      "id": "-3LGAGvV5KLE"
    },
    {
      "cell_type": "markdown",
      "id": "6f228c3e",
      "metadata": {
        "id": "6f228c3e"
      },
      "source": [
        "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "566929b7",
      "metadata": {
        "id": "566929b7"
      },
      "source": [
        "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов.\n",
        "\n",
        "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию.\n",
        "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f86878",
      "metadata": {
        "id": "81f86878"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(min_df=5, max_df=0.4, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
        "\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15af4e1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15af4e1f",
        "outputId": "94ae06d4-ed8e-4779-a3f9-c2e8ebcccf2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.85      0.87       947\n",
            "         1.0       0.74      0.80      0.77       495\n",
            "\n",
            "    accuracy                           0.83      1442\n",
            "   macro avg       0.81      0.83      0.82      1442\n",
            "weighted avg       0.84      0.83      0.84      1442\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# логистическая регрессия\n",
        "clf = LogisticRegression(penalty='l2', class_weight='balanced')\n",
        "clf.fit(X, y)\n",
        "preds = clf.predict(X_test)\n",
        "print(classification_report(y_test, preds, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "feature_importance = np.abs(clf.coef_[0])\n",
        "top_indices = feature_importance.argsort()[-5:][::-1]\n",
        "[feature_names[i] for i in top_indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWKppbLuoqmV",
        "outputId": "a50a8474-621c-4988-b634-5a6b2ebde1a9"
      },
      "id": "vWKppbLuoqmV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['хохлы', 'хохлов', 'тебе', 'дебил', 'блядь']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_df=0.01, max_features=10000, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
        "\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ],
      "metadata": {
        "id": "NtwG3Pbx9X93"
      },
      "id": "NtwG3Pbx9X93",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# дерево решений\n",
        "clf = DecisionTreeClassifier(max_depth=2000, class_weight='balanced')\n",
        "clf.fit(X, y)\n",
        "preds = clf.predict(X_test)\n",
        "print(classification_report(y_test, preds, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOPa8Eec8H_e",
        "outputId": "45210cc6-050d-4526-ecd8-f920c3bca993"
      },
      "id": "TOPa8Eec8H_e",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.79      0.83       990\n",
            "         1.0       0.62      0.74      0.67       452\n",
            "\n",
            "    accuracy                           0.78      1442\n",
            "   macro avg       0.74      0.77      0.75      1442\n",
            "weighted avg       0.79      0.78      0.78      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "feature_importance = clf.feature_importances_\n",
        "top_indices = feature_importance.argsort()[-5:][::-1]\n",
        "[feature_names[i] for i in top_indices]"
      ],
      "metadata": {
        "id": "brqnnrBG8lHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0760b867-2996-4c43-893e-7aa8c06532c0"
      },
      "id": "brqnnrBG8lHc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['очень', 'тебе', 'хохлы', 'нахуй', 'хохлов']"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=10000, max_df=0.1, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
        "\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ],
      "metadata": {
        "id": "09Q3WFYcrL-F"
      },
      "id": "09Q3WFYcrL-F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# наивный байес\n",
        "clf = MultinomialNB(alpha=1, force_alpha=True)\n",
        "clf.fit(X, y)\n",
        "preds = clf.predict(X_test)\n",
        "print(classification_report(y_test, preds, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmxcOj4EsKZu",
        "outputId": "11e1492b-d86f-4625-d49c-c8b38fb8b18c"
      },
      "id": "DmxcOj4EsKZu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.90      0.88       947\n",
            "         1.0       0.79      0.71      0.75       495\n",
            "\n",
            "    accuracy                           0.83      1442\n",
            "   macro avg       0.82      0.80      0.81      1442\n",
            "weighted avg       0.83      0.83      0.83      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "feature_importance = np.abs(clf.feature_log_prob_[1])\n",
        "top_indices = feature_importance.argsort()[-5:][::-1]\n",
        "[feature_names[i] for i in top_indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IOOHBUlsS9P",
        "outputId": "d09fc608-422e-4dfd-ff4a-d1252ad73a30"
      },
      "id": "2IOOHBUlsS9P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ёмкости', 'отправила', 'очень дорого', 'оценки', 'охраны']"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(max_features=10000, max_df=0.1, stop_words=russian_stopwords, ngram_range=(1, 3))\n",
        "\n",
        "X = vectorizer.fit_transform(train.comment)\n",
        "X_test = vectorizer.transform(test.comment)\n",
        "\n",
        "y = train.toxic.values\n",
        "y_test = test.toxic.values"
      ],
      "metadata": {
        "id": "3jM5LB1i-u_4"
      },
      "id": "3jM5LB1i-u_4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# рандомный лес\n",
        "clf = RandomForestClassifier(max_depth=1000, class_weight='balanced')\n",
        "clf.fit(X, y)\n",
        "preds = clf.predict(X_test)\n",
        "print(classification_report(y_test, preds, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeAbKdII-18i",
        "outputId": "24d52db5-7ad8-4f74-fc0f-cb1347aa7a82"
      },
      "id": "HeAbKdII-18i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.81      0.84       947\n",
            "         1.0       0.68      0.75      0.71       495\n",
            "\n",
            "    accuracy                           0.79      1442\n",
            "   macro avg       0.77      0.78      0.77      1442\n",
            "weighted avg       0.80      0.79      0.79      1442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "feature_importance = clf.feature_importances_\n",
        "top_indices = feature_importance.argsort()[-5:][::-1]\n",
        "[feature_names[i] for i in top_indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8eWPXjh-3Bz",
        "outputId": "f82bb878-2c20-4ef0-ef89-b9811803d231"
      },
      "id": "v8eWPXjh-3Bz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['очень', 'хохлы', 'тебе', 'хохлов', 'нахуй']"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}